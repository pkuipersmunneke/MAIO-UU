{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Open the data from your own station on the campus, merge data and save to one netCDF file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the location of current folder \n",
    "base_dir = sys.path[0]\n",
    "print(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to the folder with raw data from MAIO setup\n",
    "L0_folder = base_dir + \"/Data/UU_Toulouselaan_2024/L0/\"\n",
    "\n",
    "os.chdir(L0_folder)\n",
    "\n",
    "# List all the 30min data files\n",
    "files = glob.glob('*30m*.txt')\n",
    "print('input files: ', files)\n",
    "\n",
    "# open each file and merge in same dataframe\n",
    "for idx, file in enumerate(files):\n",
    "    # open CSV file\n",
    "    df = pd.read_csv(file,delimiter = ',',header=0)\n",
    "    # Rename time variable\n",
    "    df.rename(columns={'Time(UTC)': 'time'}, inplace=True)\n",
    "    # Set time variable as dataframe index\n",
    "    df = df.set_index('time')\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    if idx == 0:\n",
    "        df_out = df\n",
    "    else:\n",
    "        # merge dataframes\n",
    "        df_out = df_out.join(df, how='outer')\n",
    "\n",
    "# list variables\n",
    "print('variables: ', df_out.keys())\n",
    "\n",
    "\n",
    "# make xarray dataset from pandas dataframe\n",
    "ds = df_out.to_xarray()\n",
    "\n",
    "# Compute hourly averages\n",
    "ds_hour = ds.resample(time=\"1H\").mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to net CDF in new folder\n",
    "L1_folder  = base_dir + \"/Data/UU_Toulouselaan_2024/L1/\"\n",
    "\n",
    "name = 'MAIO'\n",
    "year = '2024'\n",
    "loc = 'UUTL'\n",
    "version = '1.0'\n",
    "level = 'L1'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L1_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# Read metadata file\n",
    "meta_file = base_dir + '/Metadata/variables.csv'\n",
    "meta = pd.read_csv(meta_file, index_col=0, comment=\"#\")\n",
    "\n",
    "# Write metadata for each variable in output file\n",
    "for var in list(ds_hour.variables):\n",
    "     for attr in list(meta.keys()):\n",
    "          if len(meta[meta.index==var][attr].values) > 0:\n",
    "               ds_hour[var].attrs[attr] = meta[meta.index==var][attr].values[0]\n",
    "     \n",
    "# add some general attributes\n",
    "ds_hour.attrs['file_creation_date_time'] = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L1_folder):\n",
    "     os.makedirs(L1_folder) \n",
    "os.chdir(L1_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds_hour.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "plt.rc('font', family='Arial')\n",
    "plt.rc('xtick', labelsize='medium')\n",
    "plt.rc('ytick', labelsize='medium')\n",
    "\n",
    "centimeters = 1/2.54  # centimeters in inches\n",
    "fig, axs = plt.subplots(3, 1, sharex=True,figsize=(20*centimeters, 20*centimeters))\n",
    "# Remove horizontal space between axes\n",
    "fig.subplots_adjust(bottom=0.15, wspace=0.05)\n",
    "\n",
    "axs[0].plot(ds.time,ds.t_1,ds.time, ds.t_2,ds.time,ds.t_3,ds.time,ds.t_4,ds.time,ds.t_5,  # data\n",
    "marker='None',     # each marker will be rendered as a circle\n",
    "markersize=10,   # marker size\n",
    "#color = '#3f79bc', # line color\n",
    "markerfacecolor='red',   # marker facecolor\n",
    "markeredgecolor='black',  # marker edgecolor\n",
    "markeredgewidth=2,       # marker edge width\n",
    "linestyle='-',            # line style will be dash line\n",
    "linewidth=3)          # line width\n",
    "axs[0].set_ylabel('$T (\\circ C)$')\n",
    "\n",
    "axs[1].plot(ds.time,ds.wspd_1,ds.time, ds.wspd_2,ds.time,ds.wspd_3,ds.time,ds.wspd_4,ds.time,ds.wspd_5,  # data\n",
    "marker='None',     # each marker will be rendered as a circle\n",
    "markersize=10,   # marker size\n",
    "#color = '#3f79bc', # line color\n",
    "markerfacecolor='red',   # marker facecolor\n",
    "markeredgecolor='black',  # marker edgecolor\n",
    "markeredgewidth=2,       # marker edge width\n",
    "linestyle='-',            # line style will be dash line\n",
    "linewidth=3)          # line width\n",
    "axs[1].set_ylabel('$wspd (ms^{-1})$')\n",
    "\n",
    "axs[2].plot(ds.time,ds.rh_1,ds.time, ds.rh_2,ds.time,ds.rh_3,ds.time,ds.rh_4,ds.time,ds.rh_5,  # data\n",
    "marker='None',     # each marker will be rendered as a circle\n",
    "markersize=10,   # marker size\n",
    "#color = '#3f79bc', # line color\n",
    "markerfacecolor='red',   # marker facecolor\n",
    "markeredgecolor='black',  # marker edgecolor\n",
    "markeredgewidth=2,       # marker edge width\n",
    "linestyle='-',            # line style will be dash line\n",
    "linewidth=3)          # line width\n",
    "axs[2].set_ylabel('$RH (\\%)$')\n",
    "\n",
    "axs[2].legend(['8 m', '4 m', '2 m', '1 m', '0.5 m'])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(L1_folder + 'timeseries.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will download data from the KNMI AWS in de Bilt :\n",
    "- Go to https://daggegevens.knmi.nl/klimatologie/uurgegevens\n",
    "- Select all parameters ('Velden'), station de Bilt, all data since 20230901 in csv format (see screenshot below)\n",
    "- save data to a new 'L0' folder in the 'KNMI_deBilt' folder \n",
    "\n",
    "![Alt text](image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open KNMI data\n",
    "# Move to the folder with raw data from KNMI website \n",
    "L0_folder = base_dir + \"/Data/KNMI_deBilt/L0/\"\n",
    "\n",
    "try:\n",
    "    os.chdir(L0_folder)\n",
    "except ValueError:\n",
    "    raise ValueError(\"KNMI data is not available\")\n",
    "\n",
    "\n",
    "# List all the data files\n",
    "files = glob.glob('*txt') # change this if you have .csv files\n",
    "print('input files: ', files)\n",
    "\n",
    "# Standard variables \n",
    "column_names = ['STN','YYYYMMDD','H',   'DD',   'FH',   'FF',   'FX',    'T', 'T10N',   'TD',   'SQ',    'Q',   'DR',   'RH',    'P',   'VV',    'N',    'U',   'WW',   'IX',    'M',    'R',    'S',    'O',    'Y']\n",
    "\n",
    "# open each file and merge in same dataframe\n",
    "for idx, file in enumerate(files):\n",
    "    # open CSV file\n",
    "    \n",
    "    df = pd.read_csv(file,delimiter = ',', comment='#',names=column_names)\n",
    "    # Rename time variable\n",
    "    # df.rename(columns={'Time(UTC)': 'time'}, inplace=True)\n",
    "    # Set time variable as dataframe index\n",
    "    # df = df.set_index('time')\n",
    "    # df.index = pd.to_datetime(df.index)\n",
    "    if idx == 0:\n",
    "        df_out = df\n",
    "    else:\n",
    "        # merge dataframes\n",
    "        df_out = df_out.join(df, how='outer')\n",
    "# Make time index\n",
    "df_out['time'] = pd.to_datetime(df_out['YYYYMMDD'], format='%Y%m%d') + pd.to_timedelta(df_out[\"H\"], unit=\"H\")\n",
    "df_out  = df_out.set_index('time')\n",
    "# list variables\n",
    "print('variables: ', df_out.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert variables\n",
    "df_out['FH'] = df_out['FH']*0.1 \n",
    "df_out['FF'] = df_out['FF']*0.1\n",
    "df_out['FX'] = df_out['FX']*0.1\n",
    "df_out['T'] = df_out['T']*0.1\n",
    "df_out['TD'] = df_out['TD']*0.1\n",
    "df_out['P'] = df_out['P']*0.1\n",
    "df_out['Q'] = df_out['Q']*1e4/3600 # from J/cm2 to W/m2 per hour\n",
    "\n",
    "# Keep variables of interest\n",
    "colums_out = ['FH','FF','FX','T','TD','P','Q']\n",
    "df_out = df_out[colums_out]\n",
    "\n",
    "# convnert to xarray dataset\n",
    "ds = df_out.to_xarray()\n",
    "\n",
    "# Export dataset to net CDF in new folder\n",
    "L1_folder  = base_dir + \"/Data/KNMI_deBilt/L1/\"\n",
    "\n",
    "name = 'KNMI_AWS'\n",
    "year = '2024'\n",
    "loc = 'deBilt'\n",
    "version = '1.0'\n",
    "level = 'L1'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L1_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# add some general attributes\n",
    "ds.attrs['file_creation_date_time']     = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L1_folder):\n",
    "     os.makedirs(L1_folder) \n",
    "os.chdir(L1_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to compare the KNMI data to our own data.\n",
    "- Open the L1 file with MAIO data\n",
    "- Open the L1 cile from KNMI data\n",
    "- Merge variables from both datasets in a new dataset\n",
    "- make some scatter plots & timeseries plots\n",
    "- save plots and data to a new L2 folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIO_folder = base_dir + \"/Data/UU_Toulouselaan_2024/L1/\"\n",
    "KNMI_folder  = base_dir + \"/Data/KNMI_deBilt/L1/\"\n",
    "\n",
    "# Open file with MAIO data\n",
    "os.chdir(MAIO_folder)\n",
    "file = glob.glob('*nc')\n",
    "ds_1 = xr.open_dataset(file[0])#,engine='scipy')\n",
    "# Open file with KNMI data\n",
    "os.chdir(KNMI_folder)\n",
    "file = glob.glob('*nc')\n",
    "ds_2 = xr.open_dataset(file[0])#,engine='scipy')\n",
    "\n",
    "# Merge dataset\n",
    "ds_out = xr.merge([ds_1,ds_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export dataset to net CDF in new folder\n",
    "L2_folder  = base_dir + \"/Data/UU_Toulouselaan_2024/L2/\"\n",
    "\n",
    "name = 'MAIO'\n",
    "year = '2024'\n",
    "loc = 'UUTL'\n",
    "version = '1.0'\n",
    "level = 'L2'\n",
    "period = '1H'\n",
    "oformat = 'nc'\n",
    "file_out = f'{L2_folder}{name}_{year}_{loc}_{level}_{period}_{version}.{oformat}'\n",
    "\n",
    "# add some general attributes\n",
    "ds_out.attrs['file_creation_date_time']     = str(datetime.datetime.now())\n",
    "\n",
    "# create output folder\n",
    "if not os.path.exists(L2_folder):\n",
    "     os.makedirs(L2_folder) \n",
    "os.chdir(L2_folder)\n",
    "\n",
    "# Export to net CDF\n",
    "ds_out.to_netcdf(file_out,mode = 'w')\n",
    "\n",
    "# go back to main folder\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot between 2 variables\n",
    "os.chdir(L2_folder)\n",
    "\n",
    "xvar = \"swd_1\" #T\n",
    "yvar = \"Q\" #t_0\n",
    "\n",
    "min = np.nanmin([np.min(ds_out[xvar]).values,np.nanmin(ds_out[yvar].values)])\n",
    "max = np.nanmax([np.max(ds_out[xvar]).values,np.nanmax(ds_out[yvar].values)])\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20*centimeters, 20*centimeters))\n",
    "plt.axline((min, min), (max, max), linewidth=1, color='k')\n",
    "\n",
    "ds_out.plot.scatter(x=xvar, y=yvar)\n",
    "plt.xlim([min,max])\n",
    "plt.ylim([min,max])\n",
    "plt.tight_layout()\n",
    "plt.savefig('scatter_%s.png'%(xvar + yvar))\n",
    "plt.show()\n",
    "\n",
    "# COmpute bias and RMSE\n",
    "bias = np.nanmean(ds_out[yvar] - ds_out[xvar])\n",
    "RMS = np.sqrt(np.nanmean((ds_out[yvar] - ds_out[xvar])**2))\n",
    "\n",
    "print('bias = ',bias)\n",
    "print('RMS = ',RMS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cauclate surface tmeperatyre\n",
    "boltz  = 5.67e-8     # Stefan-Boltzmann constant (W/m^2/K^4)\n",
    "epsilon = 0.97 # surface emissivity (-)\n",
    "ds_out['tsurf'] = (ds_out['lwu_1']/ (epsilon*boltz)) ** (1/4) - 273.15\n",
    "\n",
    "# Make a time series plot of 5 variables\n",
    "os.chdir(L2_folder)\n",
    "\n",
    "yvar_1 = \"t_1\"\n",
    "yvar_2 = \"T\"\n",
    "yvar_3 = \"Tc1\"\n",
    "yvar_4 = \"Ts\"\n",
    "yvar_5 = \"tsurf\"\n",
    "\n",
    "plt.figure(figsize=(20*centimeters, 20*centimeters))\n",
    "ds_out[yvar_1].plot.line()\n",
    "ds_out[yvar_2].plot.line()\n",
    "ds_out[yvar_3].plot.line()\n",
    "ds_out[yvar_4].plot.line()\n",
    "ds_out[yvar_5].plot.line()\n",
    "\n",
    "plt.xlim(pd.Timestamp('2024-09-17'), pd.Timestamp('2024-09-23'))\n",
    "plt.tight_layout()\n",
    "plt.legend([yvar_1, yvar_2, yvar_3, yvar_4, yvar_5])\n",
    "\n",
    "plt.savefig('timeseries_%s.png'%(yvar_1 + yvar_2 + yvar_3 + yvar_4 + yvar_5))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
